# üèÜ OscarOrNot: Predicting Oscar-Worthy Films with Neural Networks

**OscarNet** is a machine learning project designed to predict whether a film will win the **Best Picture Oscar** based on a rich set of features including box office performance, critical reception, genre, timing of release, and industry prestige indicators.

## üìå Project Objective

Leverage a neural network to classify movies as potential **Oscar winners** or not, using engineered features derived from metadata, release strategies, and historical trends in Academy Awards.

## üîç Features Used

| Feature Name                  | Use in Model | Derived/Raw         | Notes |
|------------------------------|--------------|----------------------|-------|
| **imdb_id**                  | ‚ùå           | Raw                  | Used only for web scraping; not included in training |
| **movie_id**                 | ‚ùå           | Raw                  | Unique identifier ‚Äî no predictive value |
| **name**                     | ‚úÖ           | Raw                  | May influence recognition/popularity; consider embeddings, word count, sentiment, or semantic features |
| **release_date**            | ‚ùå           | Raw                  | Used to derive other features like release_month, weeks_before_oscar |
| **release_year**            | ‚úÖ           | Derived from release_date | Temporal trend or eligibility tracking |
| **release_month**           | ‚úÖ           | Derived from release_date | Captures strategic Oscar eligibility windows |
| **release_day**             | ‚úÖ           | Derived from release_date | May help with fine-grained release timing analysis |
| **oscar_date_that_year**     | ‚ùå           | Raw                  | Used only to compute weeks_before_oscar |
| **weeks_before_oscar**       | ‚úÖ           | Derived              | Captures strategic release timing ‚Äî Oscars favor Q4 releases |
| **opening_weekend_usd**      | ‚úÖ           | Raw                  | Strong early hype signal ‚Äî log-transform recommended |
| **opening_week_usd**         | ‚ùå           | Raw                  | Redundant with weekend revenue; optional |
| **total_box_office_usd**     | ‚úÖ           | Raw                  | Indicator of overall commercial success ‚Äî normalize |
| **production_budget_usd**    | ‚úÖ           | Raw                  | Normalize; enables ROI-related calculations |
| **production_companies**     | ‚úÖ           | Derived (one-hot)    | May carry prestige or influence; encode accordingly |
| **production_countries**     | ‚úÖ           | Derived (one-hot)    | National origin may bias perception (e.g., foreign films less likely in Best Picture) |
| **language**                 | ‚úÖ           | Raw / Derived        | Replace `language_en`; multi-hot if multilingual ‚Äî English dominance noted |
| **main_genre_encoded**       | ‚úÖ           | Derived (one-hot)    | Oscars favor drama and certain genres more |
| **side_genres_multi_encoded**| ‚úÖ           | Derived (multi-hot)  | Multi-genre blends like comedy-drama often favored |
| **runtime_minutes**          | ‚úÖ           | Raw                  | Normalize; longer films favored historically |
| **is_franchise**             | ‚úÖ           | Raw                  | Franchise/MCU sequels rarely win Best Picture |
| **based_on_existing_ip**     | ‚úÖ           | Raw                  | Adaptations (books, biographies) often help ‚Äî encode as binary |
| **director_oscar_wins**      | ‚úÖ           | Raw                  | Count ‚Äî strong prestige signal |
| **director_oscar_noms**      | ‚úÖ           | Raw                  | Count ‚Äî reflects industry reputation |
| **actors_oscar_wins_total**  | ‚úÖ           | Raw                  | Sum of top-billed actors' wins |
| **actors_oscar_noms_total**  | ‚úÖ           | Raw                  | Sum ‚Äî indicator of acting quality |
| **writer_oscar_wins**        | ‚úÖ           | Raw                  | Strong proxy for screenplay quality |
| **writer_oscar_noms**        | ‚úÖ           | Raw                  | Even nominations reflect script quality |
| **rt_score_pct**             | ‚úÖ           | Raw                  | Normalize (0‚Äì100); essential critic reception indicator |
| **imdb_rating_10**           | ‚úÖ           | Raw                  | Normalize (0‚Äì10); useful but noisier than RT |
| **mdb_rating_10**            | ‚úÖ           | Raw                  | If separate from IMDb, normalize and include |
| **imdb_votes**               | ‚úÖ           | Raw                  | Helps gauge popularity and user base trust |
| **google_trends_buzz**       | ‚ö† Maybe      | Derived              | Risky: sensitive to viral, meme, or controversial noise. Needs normalization and manual quality control |

> All monetary values are normalized (log-transformed) to reduce skew. Categorical fields are one-hot or multi-hot encoded where appropriate.

## üß† Model

A fully connected feedforward **neural network** is trained using TensorFlow/Keras, with layers optimized for classification tasks (binary output: Oscar Win / No Win).

- **Loss Function**: Binary Crossentropy  
- **Optimizer**: Adam  
- **Evaluation Metrics**: Accuracy, Precision, Recall, AUC  

## üìÅ Folder Structure

to do

## License

This project (code and documentation) is licensed under the MIT License.  
See [LICENSE](./LICENSE) for more details.

### Dataset License

The dataset used in this project ‚Äî [TMDB Movies Daily Updates](https://www.kaggle.com/datasets/alanvourch/tmdb-movies-daily-updates) by Alan Vourch ‚Äî is licensed under the [Apache License 2.0](https://www.apache.org/licenses/LICENSE-2.0).

Please note that while the code in this repository is MIT-licensed, the dataset is subject to its own license and terms of use.

---
